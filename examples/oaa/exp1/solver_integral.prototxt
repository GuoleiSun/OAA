train_net: "exp1/train_integral.prototxt"
#test_iter: 0
#test_interval: 1000000
# lr for fine-tuning should be lower than when starting from scratch
lr_policy: "step"
base_lr: 1e-3
gamma: 0.1
iter_size: 5
# stepsize should also be lower, as we're closer to being done
stepsize: 20000
display: 100
average_loss: 50
max_iter: 30000
momentum: 0.9
weight_decay: 0.0002
snapshot: 1000
snapshot_prefix: "exp1/snapshot/memory1a"
# uncomment the following to default to CPU mode solving
